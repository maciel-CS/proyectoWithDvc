{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FKD9-eMp9bVv"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, json, gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\MSCS\\\\MLDeploying\\\\ProyectoFinalImages\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RxueKVcH9xDO"
   },
   "outputs": [],
   "source": [
    "ROOT = \"../dataset/images\"   # <- CAMBIA: contiene train/ val/ test/\n",
    "\n",
    "# --- Modelo: \"EfficientNetB4\" o \"EfficientNetB5\" ---\n",
    "MODEL_FAMILY = \"EfficientNetB4\"              # \"EfficientNetB5\" si prefieres\n",
    "\n",
    "# --- Tamaño de imagen según el modelo ---\n",
    "IMG_SIZE = (380, 380) if MODEL_FAMILY == \"EfficientNetB4\" else (456, 456)\n",
    "\n",
    "# --- Entrenamiento ---\n",
    "BATCH = 16                # B4: 8–16; B5: 4–8 (según VRAM)\n",
    "SEED = 42\n",
    "EPOCHS_HEAD = 10          # etapa 1 (backbone congelado)\n",
    "EPOCHS_FT   = 20          # etapa 2 (fine-tuning)\n",
    "UNFREEZE_FROM = -60       # desbloquear últimas N capas del backbone\n",
    "\n",
    "LR_HEAD = 1e-3\n",
    "LR_FT   = 1e-4\n",
    "MIXED_PRECISION = True    # activa si tu GPU lo soporta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CNHIDGMt_-hc"
   },
   "outputs": [],
   "source": [
    "# --- Cache en disco (opcional) ---\n",
    "USE_DISK_CACHE = False\n",
    "CACHE_DIR = \"/tmp/keras_cache_efficientnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UfNx9UhKxzt",
    "outputId": "5f285782-2461-4022-d87f-78e0fabad5c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: ../dataset/images | MODEL: EfficientNetB4 | IMG_SIZE: (380, 380) | BATCH: 32\n"
     ]
    }
   ],
   "source": [
    "# --- Directorio de salida ---\n",
    "OUTDIR = \"./export_efficientnet_b4_b5\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT, \"| MODEL:\", MODEL_FAMILY, \"| IMG_SIZE:\", IMG_SIZE, \"| BATCH:\", BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqpHkDvyK0vM",
    "outputId": "7b83a004-7d69-4ca2-d35f-b03af17bab32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Maciel\\anaconda3\\envs\\proyectoFinal\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "[i] Mixed precision ACTIVADA\n"
     ]
    }
   ],
   "source": [
    "# Limpieza y GPU\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for g in gpus:\n",
    "    try: tf.config.experimental.set_memory_growth(g, True)\n",
    "    except: pass\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    try:\n",
    "        from tensorflow.keras import mixed_precision\n",
    "        mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "        print(\"[i] Mixed precision ACTIVADA\")\n",
    "    except Exception as e:\n",
    "        print(\"[!] Mixed precision no disponible:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oUAz_wzK4sU",
    "outputId": "6ba5dff2-401e-4d5f-f324-0fd11dcea0f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/images\\train\n",
      "Found 12600 files belonging to 9 classes.\n",
      "Found 3600 files belonging to 9 classes.\n",
      "Found 1800 files belonging to 9 classes.\n",
      "[i] Clases: ['0_9', '10_19', '20_29', '30_39', '40_49', '50_59', '60_69', '70_79', '80_plus']\n"
     ]
    }
   ],
   "source": [
    "# ================== Carga de Datasets ==================\n",
    "train_dir = os.path.join(ROOT, \"train\")\n",
    "val_dir   = os.path.join(ROOT, \"val\")\n",
    "test_dir  = os.path.join(ROOT, \"test\")\n",
    "\n",
    "print (train_dir)\n",
    "\n",
    "# 1) Carga \"raw\" para conservar class_names antes de envolver\n",
    "raw_train_ds = keras.utils.image_dataset_from_directory(\n",
    "    train_dir, image_size=IMG_SIZE, batch_size=BATCH, seed=SEED, shuffle=True\n",
    ")\n",
    "raw_val_ds = keras.utils.image_dataset_from_directory(\n",
    "    val_dir, image_size=IMG_SIZE, batch_size=BATCH, seed=SEED, shuffle=False\n",
    ")\n",
    "raw_test_ds = keras.utils.image_dataset_from_directory(\n",
    "    test_dir, image_size=IMG_SIZE, batch_size=BATCH, seed=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# 2) class_names / num_classes\n",
    "class_names = raw_train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"[i] Clases:\", class_names)\n",
    "\n",
    "# 3) Envolver (sin cache en RAM). Puedes activar cache en DISCO si quieres\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "if USE_DISK_CACHE:\n",
    "    os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "    train_cache_file = os.path.join(CACHE_DIR, \"train.cache\")\n",
    "    val_cache_file   = os.path.join(CACHE_DIR, \"val.cache\")\n",
    "    test_cache_file  = os.path.join(CACHE_DIR, \"test.cache\")\n",
    "else:\n",
    "    train_cache_file = val_cache_file = test_cache_file = None\n",
    "\n",
    "def cfg(ds, shuffle=False, cache_file=None):\n",
    "    ds = ds.map(lambda x, y: (x, y), num_parallel_calls=2)  # limita paralelismo (RAM)\n",
    "    if cache_file:\n",
    "        ds = ds.cache(cache_file)  # cache en DISCO (opcional)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(BATCH * 8, seed=SEED)\n",
    "    return ds.prefetch(AUTOTUNE)\n",
    "\n",
    "train_ds = cfg(raw_train_ds, shuffle=True,  cache_file=train_cache_file)\n",
    "val_ds   = cfg(raw_val_ds,   shuffle=False, cache_file=val_cache_file)\n",
    "test_ds  = cfg(raw_test_ds,  shuffle=False, cache_file=test_cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fAPsnDLK6nM",
    "outputId": "4968b0dc-18b1-4ad2-bed1-a65636101a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Train counts: {'0_9': 1400, '10_19': 1400, '20_29': 1400, '30_39': 1400, '40_49': 1400, '50_59': 1400, '60_69': 1400, '70_79': 1400, '80_plus': 1400}\n",
      "[i] class_weight: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0}\n"
     ]
    }
   ],
   "source": [
    "# ================== Class Weights (opcional) ==================\n",
    "def count_images_by_class(folder, class_names):\n",
    "    counts = {}\n",
    "    for c in class_names:\n",
    "        p = os.path.join(folder, c)\n",
    "        n = sum(len(files) for _, _, files in os.walk(p)) if os.path.isdir(p) else 0\n",
    "        counts[c] = n\n",
    "    return counts\n",
    "\n",
    "train_counts = count_images_by_class(train_dir, class_names)\n",
    "total = sum(train_counts.values())\n",
    "class_weight = {}\n",
    "for i, c in enumerate(class_names):\n",
    "    n = train_counts[c]\n",
    "    class_weight[i] = (total / (num_classes * n)) if n > 0 else 0.0\n",
    "\n",
    "print(\"[i] Train counts:\", train_counts)\n",
    "print(\"[i] class_weight:\", class_weight)\n",
    "# Si quieres desactivar: pon class_weight=None en model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "oiItwrX4K8sL",
    "outputId": "df7fdd22-cb26-43a6-aa45-ef853d934a21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EfficientNetB4_clf\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"EfficientNetB4_clf\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                        </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">               Para</span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">380</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">380</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ preprocess (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">380</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">380</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">380</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">380</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ efficientnetb4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)                   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17,673,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ global_average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)                           │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)                           │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                              │                <span style=\"color: #00af00; text-decoration-color: #00af00\">16,</span>\n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m380\u001b[0m, \u001b[38;5;34m380\u001b[0m, \u001b[38;5;34m3\u001b[0m)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ preprocess (\u001b[38;5;33mLambda\u001b[0m)                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m380\u001b[0m, \u001b[38;5;34m380\u001b[0m, \u001b[38;5;34m3\u001b[0m)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m380\u001b[0m, \u001b[38;5;34m380\u001b[0m, \u001b[38;5;34m3\u001b[0m)                    │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ efficientnetb4 (\u001b[38;5;33mFunctional\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1792\u001b[0m)                   │            \u001b[38;5;34m17,673,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ global_average_pooling2d (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1792\u001b[0m)                           │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1792\u001b[0m)                           │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                              │                \u001b[38;5;34m16,\u001b[0m\n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,689,960</span> (67.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,689,960\u001b[0m (67.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,137</span> (63.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,137\u001b[0m (63.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,673,823</span> (67.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17,673,823\u001b[0m (67.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================== Modelo (EfficientNet B4/B5) ==================\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess\n",
    "\n",
    "base_cls = getattr(keras.applications, MODEL_FAMILY)  # EfficientNetB4 o EfficientNetB5\n",
    "\n",
    "# Augmentations (NO usar Rescaling cuando empleas preprocess_input de EfficientNet)\n",
    "data_aug = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "def build_model(num_classes, img_size):\n",
    "    base = base_cls(include_top=False, weights=None, input_shape=img_size + (3,))\n",
    "    base.trainable = False  # Etapa 1: congelado\n",
    "\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "    x = layers.Lambda(eff_preprocess, name=\"preprocess\")(inputs)  # CLAVE\n",
    "    x = data_aug(x)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    # Si hay mixed precision, fuerza salida en float32\n",
    "    dtype = \"float32\" if tf.keras.mixed_precision.global_policy().name == \"mixed_float16\" else None\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=dtype)(x)\n",
    "    model = keras.Model(inputs, outputs, name=f\"{MODEL_FAMILY}_clf\")\n",
    "    return model, base\n",
    "\n",
    "model, base_model = build_model(num_classes, IMG_SIZE)\n",
    "model.summary(line_length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8kZTb0xLHyu",
    "outputId": "427fcb8d-5e66-4e5b-ca78-e3895a5eb13c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m  1/394\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:31:53\u001b[0m 124s/step - accuracy: 0.0312 - loss: 2.1972"
     ]
    }
   ],
   "source": [
    "# ================== Callbacks + Etapa 1 ==================\n",
    "ckpt_dir = os.path.join(OUTDIR, \"ckpts\"); os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "cbs_head = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(ckpt_dir, \"best_head.keras\"),\n",
    "        monitor=\"val_accuracy\", save_best_only=True\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=5, restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6\n",
    "    ),\n",
    "]\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(LR_HEAD),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history_head = model.fit(\n",
    "    train_ds, validation_data=val_ds, epochs=EPOCHS_HEAD,\n",
    "    callbacks=cbs_head, class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyisMeC7TH08"
   },
   "source": [
    "(no hacer etapa 2 aun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vnY_D_bLLBu"
   },
   "outputs": [],
   "source": [
    "# ================== Etapa 2: Fine-tuning ==================\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:UNFREEZE_FROM]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(LR_FT),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "cbs_ft = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(ckpt_dir, \"best_finetuned.keras\"),\n",
    "        monitor=\"val_accuracy\", save_best_only=True\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=6, restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6\n",
    "    ),\n",
    "]\n",
    "\n",
    "history_ft = model.fit(\n",
    "    train_ds, validation_data=val_ds, epochs=EPOCHS_FT,\n",
    "    callbacks=cbs_ft, class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXarfVWEO3YF"
   },
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hU56JiPKO3Ex",
    "outputId": "e28546d5-acc2-4cc1-bc37-5dff479ba514"
   },
   "outputs": [],
   "source": [
    "# ================== Evaluación ==================\n",
    "test_loss, test_acc = model.evaluate(test_ds, verbose=1)\n",
    "print(f\"[i] Test accuracy: {test_acc:.4f}  |  loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96DTokXBO6gf"
   },
   "outputs": [],
   "source": [
    "# ================== Guardado (Keras + metadatos) ==================\n",
    "final_model_path = os.path.join(OUTDIR, \"model.keras\")\n",
    "model.save(final_model_path)\n",
    "print(f\"[i] Modelo guardado en: {final_model_path}\")\n",
    "\n",
    "with open(os.path.join(OUTDIR, \"class_names.json\"), \"w\") as f:\n",
    "    json.dump(class_names, f, indent=2)\n",
    "\n",
    "with open(os.path.join(OUTDIR, \"metrics.json\"), \"w\") as f:\n",
    "    json.dump({\n",
    "        \"test_loss\": float(test_loss),\n",
    "        \"test_accuracy\": float(test_acc),\n",
    "        \"img_size\": IMG_SIZE,\n",
    "        \"model_family\": MODEL_FAMILY,\n",
    "        \"train_counts\": train_counts\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"[i] Artefactos listos en\", OUTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMSoHVeURGSu"
   },
   "source": [
    "GUARDAR MODELO PRODUCIDO EN LA PRIMERA ETAPA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a__LUq6RMrd",
    "outputId": "d8b3eaf9-beb7-4e99-cec9-9fd136c5e193"
   },
   "outputs": [],
   "source": [
    "# ===== Guardado del modelo de ETAPA 1 (solo cabeza) con nombre informativo =====\n",
    "import os, datetime, numpy as np\n",
    "\n",
    "# mejor val_accuracy de la etapa 1\n",
    "best_val_acc_head = float(np.max(history_head.history.get(\"val_accuracy\", [0.0])))\n",
    "\n",
    "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "fname_head = f\"{MODEL_FAMILY}_HEAD_{IMG_SIZE[0]}x{IMG_SIZE[1]}_valAcc{best_val_acc_head:.3f}_{stamp}.keras\"\n",
    "\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "path_head = os.path.join(OUTDIR, fname_head)\n",
    "\n",
    "# OJO: aquí el modelo en memoria ya tiene los \"mejores pesos\" (early stopping con restore_best_weights=True)\n",
    "model.save(path_head)\n",
    "print(f\"[i] Modelo ETAPA 1 guardado en:\\n  {path_head}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yrjx9lpRXKn"
   },
   "source": [
    "INFERENCIAS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 996
    },
    "id": "TIxIk6YsRne4",
    "outputId": "c681d1d7-8cfb-4d73-ca03-3f8d17c5c02b"
   },
   "outputs": [],
   "source": [
    "# ===== Inferencia por rutas (archivos sueltos) =====\n",
    "import os, glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_image_for_model(path, img_size):\n",
    "    img = Image.open(path).convert(\"RGB\").resize(img_size)\n",
    "    arr = np.array(img, dtype=np.float32)   # el modelo aplica preprocess internamente\n",
    "    arr = np.expand_dims(arr, axis=0)       # [1,H,W,3]\n",
    "    return img, arr\n",
    "\n",
    "# Ejemplos: toma 1 imagen de cada clase (si existe)\n",
    "sample_paths = []\n",
    "for cls in class_names:\n",
    "    pattern = os.path.join(test_dir, cls, \"*\")\n",
    "    files = glob.glob(pattern)\n",
    "    if files:\n",
    "        sample_paths.append(files[0])\n",
    "    if len(sample_paths) >= 9:   # limita a 9 para el demo\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i, p in enumerate(sample_paths[:9]):\n",
    "    img, arr = load_image_for_model(p, IMG_SIZE)\n",
    "    prob = model.predict(arr, verbose=0)[0]\n",
    "    pred_idx = int(np.argmax(prob))\n",
    "    pred_cls = class_names[pred_idx]\n",
    "    conf = float(np.max(prob))\n",
    "\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img)\n",
    "    ax.set_title(f\"{os.path.basename(os.path.dirname(p))}\\nPred: {pred_cls} ({conf:.2f})\", fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Inferencia por rutas de imagen\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGfRnYWyV4xO"
   },
   "source": [
    "INFERENCIA A UN GRUPO DE IMAGENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jn9ILkGDVGHF",
    "outputId": "c0e189be-ab54-4361-a734-e17d1c11d9d9"
   },
   "outputs": [],
   "source": [
    "# --- Cargar modelo .keras que contiene Lambda(preprocess_input) en tf.keras ---\n",
    "import os, json, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "MODEL_PATH = \"/content/export_efficientnet_b4_b5/ckpts/best_head.keras\"   # <-- ajusta\n",
    "CLASS_NAMES_PATH = \"/content/export_efficientnet_b4_b5/class_names.json\"  # <-- ajusta\n",
    "\n",
    "# 1) Trae la función oficial de EfficientNet y REGÍSTRALA para deserializar Lambdas\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess\n",
    "from tensorflow.keras.utils import register_keras_serializable, get_custom_objects\n",
    "\n",
    "@register_keras_serializable(package=\"preproc\", name=\"preprocess_input\")\n",
    "def _registered_preprocess(x):\n",
    "    return eff_preprocess(x)\n",
    "\n",
    "# Por si la Lambda fue nombrada \"preprocess\"\n",
    "get_custom_objects().update({\n",
    "    \"preprocess_input\": _registered_preprocess,\n",
    "    \"preprocess\": _registered_preprocess,\n",
    "})\n",
    "\n",
    "# 2) Carga el modelo (en tf.keras NO uses safe_mode)\n",
    "model = keras.models.load_model(\n",
    "    MODEL_PATH,\n",
    "    custom_objects={\n",
    "        \"preprocess_input\": _registered_preprocess,\n",
    "        \"preprocess\": _registered_preprocess\n",
    "    }\n",
    ")\n",
    "print(\"Modelo cargado ✅\")\n",
    "\n",
    "# 3) Tamaño esperado por el modelo\n",
    "in_shape = model.inputs[0].shape\n",
    "IMG_SIZE = (int(in_shape[1]), int(in_shape[2]))\n",
    "print(\"IMG_SIZE inferida del modelo:\", IMG_SIZE)\n",
    "\n",
    "# 4) Clases (si existe el JSON)\n",
    "if os.path.exists(CLASS_NAMES_PATH):\n",
    "    with open(CLASS_NAMES_PATH) as f:\n",
    "        class_names = json.load(f)\n",
    "    print(\"Clases:\", class_names)\n",
    "else:\n",
    "    class_names = None\n",
    "    print(\"No se encontró class_names.json (se mostrarán índices).\")\n",
    "\n",
    "print(\"TF version:\", tf.__version__, \"| Keras backend:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfCvEYsSaaQA",
    "outputId": "8c592b80-7155-4df3-d0cb-9f8f9ccab8e6"
   },
   "outputs": [],
   "source": [
    "# Carga de labels (rangos de edad) con fallback\n",
    "import os, json\n",
    "from tensorflow import keras\n",
    "\n",
    "# Asegúrate de que la ruta exista (ajústala a tu carpeta real)\n",
    "CLASS_NAMES_PATH = \"/content/export_efficientnet_b4_b5/class_names.json\"\n",
    "\n",
    "# Fallback por si no existe el JSON (ajusta el orden si el tuyo es distinto)\n",
    "FALLBACK_LABELS = [\"0_9\",\"10_19\",\"20_29\",\"30_39\",\"40_49\",\"50_59\",\"60_69\",\"70_79\",\"80_plus\"]\n",
    "\n",
    "# 1) intentar leer del JSON\n",
    "if os.path.exists(CLASS_NAMES_PATH):\n",
    "    with open(CLASS_NAMES_PATH) as f:\n",
    "        class_names = json.load(f)\n",
    "else:\n",
    "    class_names = FALLBACK_LABELS\n",
    "\n",
    "# 2) sanity: si no coincide con el # de salidas del modelo, usa fallback recortado\n",
    "num_out = model.output_shape[-1]\n",
    "if len(class_names) != num_out:\n",
    "    print(f\"[!] class_names tenía {len(class_names)} entradas; el modelo tiene {num_out}. Se usará fallback.\")\n",
    "    class_names = FALLBACK_LABELS[:num_out]\n",
    "\n",
    "print(\"[i] class_names =\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VvxZ6MDLYw1h",
    "outputId": "3f14200e-030e-4f02-b12d-d47dc4c49150"
   },
   "outputs": [],
   "source": [
    "# --- Inferencia en carpeta + visualización (Colab) ---\n",
    "import os, glob, math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === CONFIG ===\n",
    "FOLDER = \"/content/drive/MyDrive/Maestria_DataScience/Modulo-13_MLOps/Dataset_TrabajoFINAL/imagenes_de_prueba\"  # <-- ajusta\n",
    "RECURSIVE = True\n",
    "BATCH_INFER = 16      # baja a 8/4 si hace falta\n",
    "MAX_PER_PAGE = 16     # 4x4\n",
    "MAX_PAGES = 10\n",
    "\n",
    "def list_images(folder, recursive=True):\n",
    "    exts = [\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.webp\"]\n",
    "    files = []\n",
    "    if recursive:\n",
    "        for ext in exts:\n",
    "            files += glob.glob(os.path.join(folder, \"**\", ext), recursive=True)\n",
    "    else:\n",
    "        for ext in exts:\n",
    "            files += glob.glob(os.path.join(folder, ext))\n",
    "    return sorted(files)\n",
    "\n",
    "def load_img_arr(path, img_size):\n",
    "    img = Image.open(path).convert(\"RGB\").resize(img_size)\n",
    "    arr = np.array(img, dtype=np.float32)   # el modelo aplica preprocess internamente\n",
    "    return img, arr\n",
    "\n",
    "def batched(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "img_paths = list_images(FOLDER, RECURSIVE)\n",
    "print(f\"Encontradas {len(img_paths)} imágenes en:\\n  {FOLDER}\")\n",
    "if not img_paths:\n",
    "    raise SystemExit(\"No se encontraron imágenes; revisa FOLDER.\")\n",
    "\n",
    "# --- Inferencia por lotes ---\n",
    "all_preds, all_confs, all_true = [], [], []\n",
    "for batch_paths in batched(img_paths, BATCH_INFER):\n",
    "    batch_imgs = []\n",
    "    for p in batch_paths:\n",
    "        _, arr = load_img_arr(p, IMG_SIZE)\n",
    "        batch_imgs.append(arr)\n",
    "    batch_x = np.stack(batch_imgs, axis=0)                # [N,H,W,3] float32\n",
    "    probs = model.predict(batch_x, verbose=0)             # modelo ya contiene preprocess\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    confs = np.max(probs, axis=1)\n",
    "\n",
    "    all_preds.extend(preds.tolist())\n",
    "    all_confs.extend(confs.tolist())\n",
    "\n",
    "    # Etiqueta \"real\" si la carpeta padre coincide con una clase conocida\n",
    "    for p in batch_paths:\n",
    "        parent = os.path.basename(os.path.dirname(p))\n",
    "        all_true.append(parent if (class_names and parent in class_names) else None)\n",
    "\n",
    "# --- Visualización paginada ---\n",
    "def show_pages(paths, preds, confs, ytrue, class_names, img_size, max_per_page=16, max_pages=10):\n",
    "    pages = min(math.ceil(len(paths)/max_per_page), max_pages)\n",
    "    for pg in range(pages):\n",
    "        start = pg * max_per_page\n",
    "        end   = min((pg+1) * max_per_page, len(paths))\n",
    "        n     = end - start\n",
    "        cols  = 4\n",
    "        rows  = math.ceil(n/cols)\n",
    "        plt.figure(figsize=(4*cols, 4*rows))\n",
    "        for i, idx in enumerate(range(start, end), start=1):\n",
    "            p = paths[idx]\n",
    "            pred_idx = int(preds[idx])\n",
    "            conf = confs[idx]\n",
    "            pred_label = class_names[pred_idx]  # <-- usa el rango de edad\n",
    "            true_cls = ytrue[idx]\n",
    "\n",
    "            img = Image.open(p).convert(\"RGB\").resize(img_size)\n",
    "            ax = plt.subplot(rows, cols, i)\n",
    "            ax.imshow(img)\n",
    "            title = f\"Pred: {pred_label} ({conf:.2f})\"\n",
    "            if true_cls is not None:\n",
    "                title = f\"GT: {true_cls}\\n\" + title\n",
    "            ax.set_title(title, fontsize=10)\n",
    "            ax.axis(\"off\")\n",
    "        plt.suptitle(f\"Página {pg+1}/{pages} — {os.path.basename(FOLDER)}\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "show_pages(img_paths, all_preds, all_confs, all_true, class_names, IMG_SIZE,\n",
    "           max_per_page=MAX_PER_PAGE, max_pages=MAX_PAGES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNMhIIuWWBL5"
   },
   "source": [
    "DESCARGAR EL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9j3c1QItWApp",
    "outputId": "bd4129f3-3340-485f-94d0-092a5564e09c"
   },
   "outputs": [],
   "source": [
    "# Descarga tu modelo y metadatos desde Colab\n",
    "import os, shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Ajusta si guardaste en otra ruta\n",
    "OUTDIR = \"/content/export_efficientnet_b4_b5/ckpts\"   # carpeta donde guardaste model.keras, class_names.json, metrics.json\n",
    "MODEL_PATH = os.path.join(OUTDIR, \"best_head.keras\")\n",
    "\n",
    "# Opción A: descargar SOLO el .keras\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"Descargando:\", MODEL_PATH)\n",
    "    files.download(MODEL_PATH)\n",
    "else:\n",
    "    print(\"No se encontró:\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmxQzvODV-LD",
    "outputId": "a06ff46f-19fb-4ddc-b32b-fa656a220ed1"
   },
   "outputs": [],
   "source": [
    "# Opción B: descargar TODO el directorio como ZIP (modelo + class_names.json + metrics.json + ckpts/)\n",
    "!zip -r /content/export_efficientnet_b4_b5.zip /content/export_efficientnet_b4_b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoFvr71GYBO5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "proyectofinal",
   "language": "python",
   "name": "proyectofinal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
